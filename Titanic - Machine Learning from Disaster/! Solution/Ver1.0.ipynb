{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Top <font color=\"blue\"></font> <a name='Top' />"
      ],
      "metadata": {
        "id": "FulOtsurtzaC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aOt20LC3zsBN"
      },
      "outputs": [],
      "source": [
        "# The following piece of code gives the opportunity to show multiple outputs\n",
        "# in one cell:\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "\n",
        "# Colorful outputs\n",
        "class bcolors:\n",
        "    RED       = '\\033[91m'\n",
        "    OKBLUE    = '\\033[94m'\n",
        "    BOLD      = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    ENDC      = '\\033[0m'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul3FVnbIivsb"
      },
      "source": [
        "<a href=#ImpLibHlprFunc>Importing Libraries & Helper Functions </a><br>\n",
        "<a href=#EDA>EDA</a><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhunulGDzsBS"
      },
      "source": [
        "<a href=#Top>Top</a>\n",
        "\n",
        "Importing Libraries & Helper Functions<font color=\"blue\"></font> <a name='ImpLibHlprFunc' />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hgKxgVZy8OiV"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import statsmodels.api as sm\n",
        "#from sklearn.metrics import mean_squared_error\n",
        "#from math import sqrt\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import linear_model, svm\n",
        "#from sklearn.linear_model import LinearRegression, Lasso\n",
        "\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score #, r2_score\n",
        "\n",
        "#from sklearn.svm import SVR\n",
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "#from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YxHyxkRyzC34"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "# 1) PrintSeparator to print lines of repeated characters passed as the second parameter for the number of lines passed in the first parameters\n",
        "def PrintSeparator(nLines=1,ch='-'):\n",
        "  for i in range(nLines):\n",
        "    print(ch*100)\n",
        "\n",
        "def cus_print(var):\n",
        "  print(\"numpy_array of type:\" , type(var))\n",
        "  PrintSeparator(nLines=1)\n",
        "  print(var)\n",
        "  PrintSeparator(nLines=2,ch='=')\n",
        "\n",
        "def cus_print_numpyarray(npAr, printArFlag=False):\n",
        "  print(\"ndim:\", npAr.ndim, \", shape: \",npAr.shape)\n",
        "  PrintSeparator(nLines=1)\n",
        "  if printArFlag:\n",
        "    print(npAr)\n",
        "  else:\n",
        "    print(\"first_element=\", npAr[0], \"last elemnent=\" , npAr[len(npAr)-1])\n",
        "\n",
        "  PrintSeparator(nLines=2,ch='=')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "53b3b992-811a-4bb8-a7c8-8b08ece495ee"
      },
      "outputs": [],
      "source": [
        "# for each column, display column name & its distinct contents ONLY in case the column has less than 6 unique values\n",
        "def get_columns_and_distinct_values(df,nunique_target=5):\n",
        "  str_=\"\"\n",
        "  ret=[]\n",
        "  for column in df:\n",
        "      columnSeriesObj = df[column]\n",
        "      nunique_this_clmn = columnSeriesObj.nunique()\n",
        "      str_ = 'Column Name: ' + column + ', Column Type: ' + str(df[column].dtype)\n",
        "      if nunique_this_clmn == 1:\n",
        "          str_ = str_ + ', Column has one unique value only and can be dropped from the dataframe'\n",
        "          ret.append(str_)\n",
        "          ret.append(\"------------------------------------------------------------\")\n",
        "      elif nunique_this_clmn <= nunique_target:\n",
        "        str_ = str_ + ', Column has ' + str(columnSeriesObj.nunique()) + ' unique value(s) : '\n",
        "        for val in columnSeriesObj.unique():\n",
        "          str_ = str_  + str(val) + \",\"\n",
        "        str_ = str_[:len(str_)-1]\n",
        "        ret.append(str_)\n",
        "        ret.append(\"------------------------------------------------------------\")\n",
        "      else:\n",
        "        str_ = str_ + ', Column has more than ' + str(nunique_target) + ' unique values'\n",
        "      #ret.append(str_)\n",
        "      #ret.append(\"==========================================================================\")\n",
        "\n",
        "  print(\"==========================================================================\")\n",
        "  columns_of_type_object = df.select_dtypes(include=['object']).columns\n",
        "  print(\"*** Columns of type object are:\", columns_of_type_object)\n",
        "  print(\"==========================================================================\")\n",
        "  columns_of_a_single_unique_value = df.columns[df.nunique() == 1]\n",
        "  print(\"*** Columns of a single unique value are:\", columns_of_a_single_unique_value, \" can be dropped\")\n",
        "  print(\"==========================================================================\")\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GLQakVZ41gL"
      },
      "source": [
        "EDA <font color=\"blue\"></font> <a name='EDA' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcghDa1jCxuz"
      },
      "source": [
        "#### Titanic Data Description\n",
        "\n",
        "Ref./Source: https://www.kaggle.com/c/titanic/data\n",
        "\n",
        "\n",
        "***Passenger ID*** to identify the passenger, numerical feature (Passenger ID/Ticket Number).\n",
        "\n",
        "***Survived*** is our label, as we can see is a binary feature, 1 if survived and 0 otherwise.\n",
        "\n",
        "***Pclass*** is the Ticket class (1 = 1st (Upper), 2 = 2nd (Middle), 3 = 3rd (lower))\n",
        "\n",
        "***Name *** is the name of the passenger\n",
        "\n",
        "***Sex*** is the gender of the passenger\n",
        "\n",
        "***Age*** is the age in years\n",
        "\n",
        "***Sibsp*** is the number of siblings / spouses aboard the Titanic\n",
        "\n",
        "***Parch*** is the number of parents / children aboard the Titanic\n",
        "\n",
        "***Ticket*** is the ticket number\n",
        "\n",
        "***Fare*** is the Passenger fare\n",
        "\n",
        "***Cabin*** is the cabin number\n",
        "\n",
        "***Embarked*** means Port of Embarkation. C = Cherbourg, Q = Queenstown, S = Southampton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNutYeBJ137r"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "44bd7af1-3f34-4416-9dd8-7d87038b7186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1fe93a9f-a5d7-43d6-dbe8-926e41cfebd5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'titanic_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7c6c08177437>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load train data from train.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtitanic_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'titanic_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtitanic_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic_train.csv'"
          ]
        }
      ],
      "source": [
        "# load train data from train.csv\n",
        "titanic_train_df = pd.read_csv(r'titanic_train.csv')\n",
        "titanic_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff1c5a89-dbf9-4bfe-9f93-71aae3b758ec"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "829SHT0YB3fF"
      },
      "source": [
        "##### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee0bd653-7864-4d95-998e-88c67991f408"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "295f3aa5-613a-420f-9f3a-6a1ab006741e"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a0d9bb7-84eb-414b-a1bc-7b1d198e9e51"
      },
      "outputs": [],
      "source": [
        "# check for NULL values\n",
        "if titanic_train_df.isnull().any().sum() > 0:\n",
        "    print(\"There are:\" , titanic_train_df.isnull().any().sum(), \"Null values in the train data\")\n",
        "else:\n",
        "    print(\"Train data is good - There is no null values in any of the columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e23556c-2eb0-4c02-8802-480fd781880b"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.describe(include = 'all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd5XxMbi4N0C"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.drop(['Name','Ticket','PassengerId'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "430768cf-5814-458d-b57e-e72b43fcae3c"
      },
      "outputs": [],
      "source": [
        "print (\"titanic_train_df:\")\n",
        "#print(\"null values:\\n\", titanic_train_df.isnull().sum())\n",
        "print(\"duplicated records\", titanic_train_df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXZPBf8JIDUn"
      },
      "source": [
        "###### Embarked Feature / Two Records with Nan values - replace the 2 NULL values in embarked with S = Southampton (as most passengers on Titanic embarked from this port)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14052376-cfea-4074-83b1-79361fc559e9"
      },
      "outputs": [],
      "source": [
        "# Two records in titanic_train_df with Nan in Embarked feature  - will be dropped from the dataframe\n",
        "titanic_train_df[titanic_train_df['Embarked'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c645953-0cc9-4b6e-b5f1-2c1425dd801c"
      },
      "outputs": [],
      "source": [
        "print(titanic_train_df['Embarked'].value_counts())\n",
        "# most passengers are emabrked from S = Southampton (Three ports of Embarkation C = Cherbourg; Q = Queenstown; S = Southampton)\n",
        "\n",
        "# replace the 2 NULL values in embarked with S = Southampton (as most passengers on Titanic embarked from this port)\n",
        "titanic_train_df.loc[titanic_train_df['Embarked'].isnull(),'Embarked'] = 'S'\n",
        "\n",
        "print(titanic_train_df['Embarked'].value_counts())\n",
        "\n",
        "titanic_train_df[titanic_train_df['Embarked'].isnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_JHfISYII27"
      },
      "source": [
        "###### Cabin Feature / replace missing values in titanic_train_df['Cabin'] with letter 'U' for unknown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JrwJBq0Iqkr"
      },
      "outputs": [],
      "source": [
        "print(\"null values in the Cabin Feature:\\n\", titanic_train_df.isnull().sum()['Cabin'], \"Records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnIELhsEFphy"
      },
      "outputs": [],
      "source": [
        "titanic_train_df['Cabin'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQpc2J8JHyxk"
      },
      "outputs": [],
      "source": [
        "# keep first letter only in the Cabin\n",
        "titanic_train_df['Cabin'] = titanic_train_df['Cabin'].str[0]\n",
        "titanic_train_df['Cabin'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTWOaQQqI7Ps"
      },
      "outputs": [],
      "source": [
        "# replace missing values in titanic_train_df['Cabin'] with letter 'U' for unknown\n",
        "titanic_train_df['Cabin'].fillna('U', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx1od_ToJz-7"
      },
      "outputs": [],
      "source": [
        "titanic_train_df['Cabin'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByNWSp7ZKAJj"
      },
      "source": [
        "###### Age Feature / replace missing values in titanic_train_df['Age'] with the avergae of age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRQEABCjKMbr"
      },
      "outputs": [],
      "source": [
        "print(\"null values in the Age Feature:\\n\", titanic_train_df.isnull().sum()['Age'], \"Records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBI9IeedKlsz"
      },
      "outputs": [],
      "source": [
        "# Fill missing/Nan values in Age with average age\n",
        "titanic_train_df['Age'].fillna(titanic_train_df['Age'].mean(), inplace=True)  # 29.642093\n",
        "print(\"null values in the Age Feature:\\n\", titanic_train_df.isnull().sum()['Age'], \"Records\")\n",
        "#titanic_train_df['Age'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hQ_WiiuLYzk"
      },
      "outputs": [],
      "source": [
        "# Check again after fixing missing records\n",
        "titanic_train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFnqcIxjLcT7"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.describe(include = 'all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73YNRjkoM3pN"
      },
      "outputs": [],
      "source": [
        "titanic_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3631e7b-3417-4606-ab37-28a4460d2d79"
      },
      "outputs": [],
      "source": [
        "ret=get_columns_and_distinct_values(titanic_train_df,10)\n",
        "for str_ in ret:\n",
        "  print(str_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJnmuudNbH35"
      },
      "source": [
        "###### Use data for ***Fare & Cabin*** to provide ***better/more accurate*** values for the \"U = Unknown\" cabins for some/many records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1R3l751bjif"
      },
      "outputs": [],
      "source": [
        "# plot using box plot to check for outliers of Fare for the Unknown Cabins (Train df)\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.title(\"Box plot for Fare per Cabin - Titanic Train df\")\n",
        "sns.boxplot(x='Cabin', y='Fare',data=titanic_train_df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFsh9cUabqQR"
      },
      "outputs": [],
      "source": [
        "def cbnFareDataToDataFrame(titanic_df):\n",
        "  CntCbnFare, MinCbnFare, MaxCbnFare, AvgCbnFare, MedianCbnFare, ModeCbnFare = [],[],[],[],[],[]\n",
        "  for cbn in titanic_df['Cabin'].unique(): #'ABCDEFGTU':\n",
        "    condition = (titanic_df['Cabin'] == cbn) & (titanic_df['Fare']!=0)\n",
        "\n",
        "    #strCbnFareInfo = \"For Cabin: \" + cbn\n",
        "\n",
        "    cnt=titanic_df[condition]['Fare'].count()\n",
        "    #strCbnFareInfo += \" ===> Count=\" + str(cnt)\n",
        "    CntCbnFare.append(cnt)\n",
        "\n",
        "    min_=round(titanic_df[condition]['Fare'].min(),2)\n",
        "    #strCbnFareInfo += \", Min Fare=\" + str(min)\n",
        "    MinCbnFare.append(min_)\n",
        "\n",
        "    max_=round(titanic_df[condition]['Fare'].max(),2)\n",
        "    #strCbnFareInfo += \", Max=\" + str(max_)\n",
        "    MaxCbnFare.append(max_)\n",
        "\n",
        "    Mean_=round(titanic_df[condition]['Fare'].mean(),2)\n",
        "    #strCbnFareInfo += \", Mean=\" + str(Mean_)\n",
        "    AvgCbnFare.append(Mean_)\n",
        "\n",
        "    Median_=round(titanic_df[condition]['Fare'].median(),2)\n",
        "    #strCbnFareInfo += \", Median=\" + str(Median_)\n",
        "    MedianCbnFare.append(Median_)\n",
        "\n",
        "    Mode_=round(titanic_df[condition]['Fare'].mode().mean(),2)\n",
        "    #strCbnFareInfo += \", Mode=\" + str(Mode_)\n",
        "    ModeCbnFare.append(Mode_)\n",
        "\n",
        "  #print(strCbnFareInfo)\n",
        "\n",
        "  dict = {'Cbn': list(titanic_df['Cabin'].unique()), 'Count': CntCbnFare, 'Min': MinCbnFare, 'Max': MaxCbnFare, 'Mean': AvgCbnFare, 'Median': MedianCbnFare, 'Mode': ModeCbnFare}\n",
        "  cbnFareDf = pd.DataFrame(dict)\n",
        "  cbnFareDf.head(len(titanic_df['Cabin'].unique()))\n",
        "\n",
        "  #print(cbnFareDf.sort_values(by=['Median','Mean', 'Mode'], ascending=[True,True, True]))\n",
        "  return cbnFareDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xM4RMxhqevX"
      },
      "outputs": [],
      "source": [
        "cbnFareTrainDf = cbnFareDataToDataFrame(titanic_train_df)\n",
        "#cbnFareDf.head(len('ABCDEFGTU'))\n",
        "print(cbnFareTrainDf.sort_values(by=['Mean','Median','Mode'], ascending=[False,False, False]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfXOxnc5dwkJ"
      },
      "outputs": [],
      "source": [
        "# first obsevation (only for titanic train) that there is only one entry for cabin T so high probability\n",
        "# it is a data-issue - will fix to Cabin A as same Mode & closed Median & Mean\n",
        "titanic_train_df.loc[titanic_train_df['Cabin'] == 'T', 'Cabin'] = 'A'\n",
        "\n",
        "cbnFareTrainDf = cbnFareDataToDataFrame(titanic_train_df)\n",
        "print(cbnFareTrainDf.sort_values(by=['Mean','Median','Mode'], ascending=[False,False, False]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ujLEWSkp8VN"
      },
      "outputs": [],
      "source": [
        "# second obsevation that there are many entries for cabin U which has many outliers (also from the above boxplot)\n",
        "# so fix this data issue by assigning a different cabin based on fare Mean\n",
        "#print(cbnFareTrainDf.sort_values(by=['Max'], ascending=[False]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rztE8nCsQMB"
      },
      "outputs": [],
      "source": [
        "cndTrain1 = (titanic_train_df['Cabin'] == 'U')\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] > 100.15)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'B'\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] <= 100.15) & (titanic_train_df['Fare'] > 57.24)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'C'\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] <= 57.24) & (titanic_train_df['Fare'] > 46.03)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'D'\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] <= 46.03) & (titanic_train_df['Fare'] > 41.99)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'E'\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] <= 41.99) & (titanic_train_df['Fare'] > 18.70)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'A'\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] <= 18.70) & (titanic_train_df['Fare'] > 13.58)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'F'\n",
        "\n",
        "cndTrain2 = (titanic_train_df['Fare'] <= 13.58) & (titanic_train_df['Fare'] > 7.65)\n",
        "titanic_train_df.loc[cndTrain1 & cndTrain2, 'Cabin'] = 'G'\n",
        "\n",
        "#print(\"For Training Data\")\n",
        "cbnFareTrainDf = cbnFareDataToDataFrame(titanic_train_df)\n",
        "print(cbnFareTrainDf.sort_values(by=['Max'], ascending=[False]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLPYEAMCtGHq"
      },
      "outputs": [],
      "source": [
        "# plot using box plot to check for Fare per Cabin after above step (Train)\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.title(\"Box plot for Fare per Cabin\")\n",
        "sns.boxplot(x='Cabin', y='Fare',data=titanic_train_df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ2VMz7O3cug"
      },
      "outputs": [],
      "source": [
        "titanic_train_df2 = pd.get_dummies(titanic_train_df)\n",
        "titanic_train_df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNHdlGkp26UV"
      },
      "source": [
        "### **C.1.2. Data split: Traing set & Test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfsNqE7BS877"
      },
      "outputs": [],
      "source": [
        "X_tnc_train=titanic_train_df2.drop(['Survived'],axis=1)\n",
        "y_tnc_train=titanic_train_df2['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDsZ7uBmBa39"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_tnc_train,y_tnc_train,test_size=0.2)\n",
        "\n",
        "# scale data separately for train and test\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq3mhC95PLo0"
      },
      "source": [
        "### **C.1.3. Applying Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8zSEeX7TwVr"
      },
      "outputs": [],
      "source": [
        "rfc= RandomForestClassifier(n_estimators=100,random_state=47)\n",
        "rfc.fit(X_train_scaled,y_train)\n",
        "y_train_predict_rfc=rfc.predict(X_train_scaled)\n",
        "\n",
        "print(\"train accuracy_score\", accuracy_score(y_train, y_train_predict_rfc))\n",
        "print(\"train f1_score\", f1_score(y_train, y_train_predict_rfc, average=\"macro\"))\n",
        "print(\"train precision_score\",precision_score(y_train, y_train_predict_rfc, average=\"macro\"))   # \"macro\" ---> does not take into account imbalance\n",
        "print(\"train recall_score\",recall_score(y_train, y_train_predict_rfc, average=\"macro\"))\n",
        "print(\"test rfc score\",rfc.score(X_train_scaled,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szE6Eb0uUAbk"
      },
      "outputs": [],
      "source": [
        "y_test_predict_rfc = rfc.predict(X_test_scaled)\n",
        "print(\"test accuracy_score\", accuracy_score(y_test, y_test_predict_rfc))\n",
        "print(\"test f1_score\",f1_score(y_test, y_test_predict_rfc, average=\"macro\"))\n",
        "print(\"test precision_score\",precision_score(y_test, y_test_predict_rfc, average=\"macro\"))   # \"macro\" ---> does not take into account imbalance\n",
        "print(\"test recall_score\",recall_score(y_test, y_test_predict_rfc, average=\"macro\"))\n",
        "print(\"test rfc score\",rfc.score(X_test_scaled,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cfFhhX8ZyMt"
      },
      "outputs": [],
      "source": [
        "figsize = plt.figure(figsize = (12,8))\n",
        "# Initialize the accuracy_score vector\n",
        "acc = []              # test accuracy\n",
        "acc_train = []        # train accuracy\n",
        "estimators = 2 ** np.arange(9)\n",
        "print(estimators)\n",
        "\n",
        "# Calculate accuracy score on the test set for different values for the n_estimators parameter\n",
        "for est in estimators:\n",
        "    # Fit the Regression Tree\n",
        "    rfc2 = RandomForestClassifier(n_estimators=est, random_state=47) #max_depth=i,\n",
        "    rfc2.fit(X_train_scaled,y_train)\n",
        "    # Predict on the test set\n",
        "    y_pred = rfc2.predict(X_test_scaled)\n",
        "    # Compute the accuracy\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    acc.append(score)\n",
        "    acc_train.append(accuracy_score(y_train, rfc2.predict(X_train_scaled)))\n",
        "\n",
        "# Plot results\n",
        "#print(acc)\n",
        "#print(acc_train)\n",
        "plot = plt.plot(estimators, acc, '-', estimators, acc_train, 'r')\n",
        "#plot = plt.plot(estimators, acc_train, 'b', label='Train')\n",
        "#plot = plt.plot(estimators, acc, 'r', label='Test')\n",
        "xlab = plt.xlabel('# estimators', fontsize = 17)\n",
        "ylab = plt.ylabel('Accuracy', fontsize = 17)\n",
        "plt.legend(['Train','Test'])\n",
        "title = plt.title('Random Forest - Accuracy vs Depth of Trees (Titanic)', fontsize = 20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2vpa3MC5AN-"
      },
      "source": [
        "#### ***Random Forest Accuracy Results***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6v8-v-qazWV"
      },
      "outputs": [],
      "source": [
        "# best value for estimators:\n",
        "print(\"Using Random forest with different number of estimators, best accuracy was at\", max(acc),\"and it occurs when estimators=\", estimators[acc.index(max(acc))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W31cvFsHPGrs"
      },
      "source": [
        "### **C.1.4. Applying SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZwHhVID4ciD"
      },
      "outputs": [],
      "source": [
        "svc=SVC(C=1000) #kernel='rbf',\n",
        "svc.fit(X_train_scaled,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGjo665f9T7v"
      },
      "outputs": [],
      "source": [
        "y_train_predict_svc=svc.predict(X_train_scaled)\n",
        "\n",
        "print(\"train accuracy_score\", accuracy_score(y_train, y_train_predict_svc))\n",
        "print(\"train f1_score\", f1_score(y_train, y_train_predict_svc, average=\"macro\"))\n",
        "print(\"train precision_score\",precision_score(y_train, y_train_predict_svc, average=\"macro\"))   # \"macro\" ---> does not take into account imbalance\n",
        "print(\"train recall_score\",recall_score(y_train, y_train_predict_svc, average=\"macro\"))\n",
        "print(\"test svc score\",svc.score(X_train_scaled,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEgO-VsS9_WH"
      },
      "outputs": [],
      "source": [
        "y_test_predict_svc = svc.predict(X_test_scaled )\n",
        "print(\"test accuracy_score\", accuracy_score(y_test, y_test_predict_svc))\n",
        "print(\"test f1_score\",f1_score(y_test, y_test_predict_svc, average=\"macro\"))\n",
        "print(\"test precision_score\",precision_score(y_test, y_test_predict_svc, average=\"macro\"))   # \"macro\" ---> does not take into account imbalance\n",
        "print(\"test recall_score\",recall_score(y_test, y_test_predict_svc, average=\"macro\"))\n",
        "print(\"test svc score\",svc.score(X_test_scaled,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YctJzdKt5_Hn"
      },
      "outputs": [],
      "source": [
        "figsize = plt.figure(figsize = (12,8))\n",
        "# Initialize the accuracy_score vector\n",
        "acc = []              # test accuracy\n",
        "acc_train = []        # train accuracy\n",
        "reglCs = 2 ** np.arange(9)\n",
        "print(reglCs)\n",
        "\n",
        "# Calculate accuracy score on the test set for different values for the regularization parameter C\n",
        "for C_param in reglCs:\n",
        "    # Fit the Regression Tree\n",
        "    svc2 = SVC(C=C_param) #max_depth=i,\n",
        "    svc2.fit(X_train_scaled,y_train)\n",
        "    # Predict on the test set\n",
        "    y_pred = svc2.predict(X_test_scaled)\n",
        "    # Compute the accuracy\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    acc.append(score)\n",
        "    acc_train.append(accuracy_score(y_train, svc2.predict(X_train_scaled)))\n",
        "\n",
        "# Plot results\n",
        "#print(acc)\n",
        "#print(acc_train)\n",
        "plot = plt.plot(reglCs, acc, '-', reglCs, acc_train, 'r')\n",
        "#plot = plt.plot(reglCs, acc_train, 'b', label='Train')\n",
        "#plot = plt.plot(reglCs, acc, 'r', label='Test')\n",
        "xlab = plt.xlabel('Reg. Parameter C', fontsize = 17)\n",
        "ylab = plt.ylabel('Accuracy', fontsize = 17)\n",
        "plt.legend(['Train','Test'])\n",
        "title = plt.title('SVM - Accuracy vs Depth of Trees (Titanic)', fontsize = 20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM1lphuq0V4E"
      },
      "source": [
        "#### ***SVM Accuracy Results***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcY6M7765Wf8"
      },
      "outputs": [],
      "source": [
        "# best value for estimators:\n",
        "print(\"Using SVM with different values for the regularization parameter C, best accuracy was at\", max(acc),\"and it occurs when C=\", reglCs[acc.index(max(acc))])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7GLQakVZ41gL",
        "2h-1Qd-kPJSd",
        "xNHdlGkp26UV",
        "Cq3mhC95PLo0",
        "W31cvFsHPGrs"
      ],
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}